{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\"/>\n",
    "\n",
    "# Cours TAL - Laboratoire 6\n",
    "# Trois méthodes de désambiguïsation lexicale\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "L'objectif de ce laboratoire est d'implémenter et de comparer plusieurs méthodes de désambiguïsation lexicale (en anglais, *Word Sense Disambiguation* ou WSD).  Vous utiliserez un corpus avec plusieurs milliers de phrases, chaque phrase contenant une occurrence du mot anglais *interest* annotée avec le sens que ce mot possède dans la phrase respective.  Les trois méthodes sont les suivantes (elles seront détaillées par la suite) :\n",
    "\n",
    "* Algorithme de Lesk simplifié.\n",
    "* Utilisation de word2vec.\n",
    "* Classification supervisée utilisant des traits lexicaux.\n",
    "\n",
    "Les deux premières méthodes n'utilisent pas l'apprentissage automatique.  Elles fonctionnent selon le même principe : comparer le contexte d'une occurrence de *interest* avec chacune des définitions des sens (*synsets*) et choisir la définition la plus proche du contexte.  L'algorithme de Lesk définit la proximité comme le nombre de mots en commun, alors que word2vec la calcule comme la similarité de vecteurs.  La dernière méthode vise à classifier les occurrences de *interest*, les sens étant les classes, et les attributs étant les mots du contexte (apprentissage supervisé)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyse des données\n",
    "\n",
    "Téléchargez le corpus *interest* depuis le [site du Prof. Ted Pedersen](http://www.d.umn.edu/~tpederse/data.html) (il se trouve en bas de sa page web).  Téléchargez l'archive ZIP marquée *original format without POS tags* et extrayez le fichier `interest-original.txt`.  Téléchargez également le fichier `README.int.txt` indiqué à la ligne au-dessus. Veuillez répondre brièvement aux questions suivantes :\n",
    "\n",
    "a. Quelles sont les URL du fichier ZIP et celle du fichier `README.int.txt` ?\n",
    "\n",
    "b. Quel est le format du fichier `interest-original.txt` et comment sont annotés les sens de *interest* ?\n",
    "\n",
    "c. Est-ce qu'il y a aussi des occurrences au pluriel (*interests*) à traite ?\n",
    "\n",
    "d. Comment sont annotées les phrases qui contiennent plusieurs occurrences du mot *interest* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Veuillez répondre ici (en commentaire) à la question.\n",
    "\n",
    "a. Voici l'URL du ZIP : https://www.d.umn.edu/~tpederse/Data/interest-original.nopos.tar.gz <br>Voici l'URL du fichier : https://www.d.umn.edu/~tpederse/Data/README.int.txt\n",
    "\n",
    "b. C'est un fichier texte où chaque phrase est délimitée par une ligne contenant \"$$\", chaque sens est annoté comme ceci interest_{numéro du sens}\n",
    "\n",
    "c. Oui, le pluriel est le singulier sont traités\n",
    "\n",
    "d. Une occurrence par phrase est annotée avec un tag de sens (ex: _1 à _6). Les autres occurrences du mot \"interest\" dans la même phrase sont marquées par un astérisque (*) placé juste avant le mot (ex: *interest) pour indiquer qu'elles ne sont pas l'objet de l'annotation de sens pour cette instance spécifique du corpus. Cela permet de respecter la consigne \"une occurrence étiquetée par phrase\" tout en conservant le contexte phrastique complet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1e.** D'après le fichier `README.int.txt`, quelles sont les définitions des six sens de *interest* annotés dans les données et quelles sont leurs fréquences ? Vous pouvez copier/coller l'extrait de `README`ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Veuillez répondre ici (en commentaire) à la question.\n",
    "```text\n",
    "Sense 1 =  361 occurrences (15%) - readiness to give attention\n",
    "Sense 2 =   11 occurrences (01%) - quality of causing attention to be given to\n",
    "Sense 3 =   66 occurrences (03%) - activity, etc. that one gives attention to\n",
    "Sense 4 =  178 occurrences (08%) - advantage, advancement or favor\n",
    "Sense 5 =  500 occurrences (21%) - a share in a company or business\n",
    "Sense 6 = 1252 occurrences (53%) - money paid for the use of money\n",
    "\t  ----\n",
    "\t  2368 occurrences in the sense tagged corpus, where each\n",
    "\toccurrence is a single sentence that contains the word 'interest'.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1f.** De quel dictionnaire viennent les sens précédents ? Où peut-on le consulter en ligne ?  Veuillez aligner les définitions du dictionnaire avec les six sens annotés en écrivant par exemple `Sense 3 = \"an activity that you enjoy doing or a subject that you enjoy studying\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Veuillez répondre ici (en commentaire) à la question.\n",
    "\n",
    "Le dictionnaire est \"The first edition of Longman's Dictionary of Contemporary English\", on peut le consulter ici https://www.ldoceonline.com/dictionary/\n",
    "```text\n",
    "Sense 1 = \"if you have an interest in something or someone, you want to know or learn more about them\"\n",
    "Sense 2 = \"a quality or feature of something that attracts your attention or makes you want to know more about it\"\n",
    "Sense 3 = \"an activity that you enjoy doing or a subject that you enjoy studying\"\n",
    "Sense 4 = \"the things that bring advantages to someone or something\"\n",
    "Sense 5 = \"if you have an interest in a particular company or industry, you own shares in it\"\n",
    "Sense 6 = \"the extra money that you must pay back when you borrow money\" & \"money paid to you by a bank or financial institution when you keep money in an account there\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1g.** En consultant [WordNet en ligne](http://wordnetweb.princeton.edu/perl/webwn), trouvez les définitions des synsets  pour le **nom commun** *interest*.  Combien de synsets y a-t-il ?  Veuillez indiquer comme avant la **définition** de chaque synset pour chacun des six sens ci-dessus (au besoin, fusionner ou ignorer des synsets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Veuillez répondre ici (en commentaire) à la question.\n",
    "\n",
    "Il y a 7 synsets: \n",
    "\n",
    "```text\n",
    "Sense 1 = \"a sense of concern with and curiosity about someone or something\"\n",
    "Sense 2 = \"the power of attracting or holding one's attention (because it is unusual or exciting etc.)\"\n",
    "Sense 3 = \"a diversion that occupies one's time and thoughts (usually pleasantly)\"\n",
    "Sense 4 = \"a reason for wanting something done\"\n",
    "Sense 5 = \"a right or legal share of something; a financial involvement with something\"\n",
    "Sense 6 = \"a fixed charge for borrowing money; usually a percentage of the amount borrowed\"\n",
    "```\n",
    "\n",
    "On a ignoré le sens suivant : \"(usually plural) a social group whose members control some field of activity and who have common aims\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1h.** Définissez (manuellement, ou avec quelques lignes de code) une liste nommée `senses1` avec les mots des définitions du README, en supprimant les stopwords (p.ex. les mots < 4 lettres).  Affichez la liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question et créer la variable 'senses1' (liste de 6 listes de chaînes).\n",
    "senses1 = [\n",
    "    ['readiness', 'give', 'attention'],\n",
    "    ['quality', 'causing', 'attention', 'given'],\n",
    "    ['activity', 'attention'],\n",
    "    ['advantage', 'advancement', 'favor'],\n",
    "    ['share', 'company', 'business'],\n",
    "    ['money', 'paid', 'money']\n",
    "]\n",
    "print(senses1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1i.** En combinant les définitions obtenues aux points (4) et (5) ci-dessus, construisez une liste nommée `senses2` avec pour chacun des sens de *interest* une liste de **mots-clés** correspondants.  Vous pouvez concaténer les définitions, puis écrire des instructions en Python pour extraire les mots (uniques).  Respectez l'ordre des sens données par `README`, et à la fin affichez `senses2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "try:\n",
    "    word_tokenize(\"test\")\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "LDOCE = [\n",
    "    \"if you have an interest in something or someone, you want to know or learn more about them\",\n",
    "    \"a quality or feature of something that attracts your attention or makes you want to know more about it\",\n",
    "    \"an activity that you enjoy doing or a subject that you enjoy studying\",\n",
    "    \"the things that bring advantages to someone or something\",\n",
    "    \"if you have an interest in a particular company or industry, you own shares in it\",\n",
    "    \"the extra money that you must pay back when you borrow money\" + \" \" + \"money paid to you by a bank or financial institution when you keep money in an account there\"\n",
    "]\n",
    "\n",
    "WNET = [\n",
    "    \"a sense of concern with and curiosity about someone or something\",\n",
    "    \"the power of attracting or holding one's attention (because it is unusual or exciting etc.)\",\n",
    "    \"a diversion that occupies one's time and thoughts (usually pleasantly)\",\n",
    "    \"a reason for wanting something done\",\n",
    "    \"a right or legal share of something; a financial involvement with something\",\n",
    "    \"a fixed charge for borrowing money; usually a percentage of the amount borrowed\"\n",
    "]\n",
    "\n",
    "combined_definitions_text = []\n",
    "for i in range(len(LDOCE)):\n",
    "    combined_definitions_text.append(LDOCE[i] + \" \" + WNET[i])\n",
    "\n",
    "senses2 = []\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('etc')\n",
    "punctuation_chars = set(string.punctuation)\n",
    "\n",
    "\n",
    "for definition_text in combined_definitions_text:\n",
    "    text_lower = definition_text.lower()\n",
    "\n",
    "    tokens = word_tokenize(text_lower)\n",
    "\n",
    "    keywords_for_this_sense = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha() and token not in stop_words:\n",
    "            keywords_for_this_sense.append(token)\n",
    "\n",
    "    unique_keywords = sorted(list(set(keywords_for_this_sense)))\n",
    "    senses2.append(unique_keywords)\n",
    "\n",
    "print(senses2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1j.** Chargez les données depuis `interest-original.txt` dans une liste appelée `sentences` qui contient pour chaque phrase la liste des mots (sans les séparateurs *$$* et *===...*).  Ces phrases sont-elles déjà tokenisées en mots ?  Sinon, faites-le.  À ce stade, ne modifiez pas encore les occurrences annotées *interest(s)\\_X*.  Comptez le nombre total de phrases et affichez-en trois au hasard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n",
    "sentences = []\n",
    "\n",
    "filename = \"interest-original.txt\"\n",
    "\n",
    "sentences = []\n",
    "raw_lines_count = 0\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    current_sentence_words = []\n",
    "    for line in f:\n",
    "        raw_lines_count += 1\n",
    "        line_stripped = line.strip()\n",
    "\n",
    "        if line_stripped == \"$$\":\n",
    "            if current_sentence_words:\n",
    "                sentences.append(current_sentence_words)\n",
    "                current_sentence_words = []\n",
    "        elif line_stripped.startswith(\"======================================\"):\n",
    "            continue\n",
    "        elif line_stripped:\n",
    "            words_in_line = line_stripped.split()\n",
    "            current_sentence_words.extend(words_in_line)\n",
    "\n",
    "    if current_sentence_words:\n",
    "        sentences.append(current_sentence_words)\n",
    "        \n",
    "print(\"Il y a {} phrases.\\nEn voici 3 au hasard :\".format(len(sentences)))\n",
    "print(sentences[151:154])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithme de Lesk simplifié\n",
    "\n",
    "**2a.** Définissez une fonction `wsd_lesk(senses, sentence)` qui prend deux arguments : une liste de listes de mots-clés (comme `senses1` et `senses2` ci-dessus) et une phrase avec une occurrence annotée de *interest* ou *interests*, et qui retourne l'index du sens le plus probable (entre 1 et 6) selon l'algorithme de Lesk.  Cet algorithme choisit le sens qui a le maximum de mots en commun avec le contexte de *interest*.  Vous pouvez choisir vous-mêmes la taille de ce voisinage (`window_size`).  En cas d'égalité entre deux sens, tirer la réponse au sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "\n",
    "def wsd_lesk(senses, sentence, window_size=5):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    target_word_index = -1\n",
    "    for i, token in enumerate(sentence):\n",
    "        if token.startswith(\"interest_\") or token.startswith(\"interests_\"):\n",
    "            target_word_index = i\n",
    "            break\n",
    "\n",
    "    if target_word_index == -1:\n",
    "        return None\n",
    "\n",
    "    start_index = max(0, target_word_index - window_size)\n",
    "    end_index = min(len(sentence), target_word_index + window_size + 1)\n",
    "    context_tokens_raw = sentence[start_index:target_word_index] + sentence[target_word_index+1:end_index]\n",
    "\n",
    "    context_cleaned = set()\n",
    "    for token in context_tokens_raw:\n",
    "        token_lower = token.lower()\n",
    "        if token_lower.isalpha() and token_lower not in stop_words:\n",
    "            context_cleaned.add(token_lower)\n",
    "    \n",
    "    if not context_cleaned:\n",
    "        return random.randint(1, len(senses))\n",
    "\n",
    "    best_sense_indices = []\n",
    "    max_overlap = -1\n",
    "\n",
    "    for i, sense_kws in enumerate(senses):\n",
    "        sense_kws_set = set(sense_kws)\n",
    "        overlap = len(context_cleaned.intersection(sense_kws_set))\n",
    "\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense_indices = [i + 1]\n",
    "        elif overlap == max_overlap and max_overlap != -1:\n",
    "            best_sense_indices.append(i + 1)\n",
    "    \n",
    "    if not best_sense_indices:\n",
    "        return random.randint(1, len(senses))\n",
    "    elif len(best_sense_indices) == 1:\n",
    "        return best_sense_indices[0]\n",
    "    else:\n",
    "        return random.choice(best_sense_indices) # Tirer la réponse au sort parmi les meilleurs\n",
    "\n",
    "\n",
    "print(wsd_lesk(senses1, sentences[11]))\n",
    "print(wsd_lesk(senses2, sentences[11]))\n",
    "\n",
    "print(senses2[4])\n",
    "print(sentences[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b.** Définissez maintenant une fonction `evaluate_wsd(fct_name, senses, sentences)` qui prend en paramètre le nom de la méthode de similarité (pour commencer : `wsd_lesk`) ainsi que la liste des mots-clés par sens, et la liste de phrases, et qui retourne le score de la méthode de similarité.  Ce score sera tout simplement le pourcentage de réponses correctes (sens trouvé identique au sens annoté)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n",
    "import random\n",
    "from nltk.corpus import stopwords # Nécessaire si wsd_lesk l'utilise en interne\n",
    "\n",
    "def evaluate_wsd(wsd_function, senses_keywords, sentences_data, window_size=5):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for sentence_tokens in sentences_data:\n",
    "        true_sense = None\n",
    "        for token in sentence_tokens:\n",
    "            if token.startswith(\"interest_\") or token.startswith(\"interests_\"):\n",
    "                try:\n",
    "                    sense_part = token.split('_')[-1]\n",
    "                    numeric_sense_str = \"\"\n",
    "                    for char in sense_part:\n",
    "                        if char.isdigit():\n",
    "                            numeric_sense_str += char\n",
    "                        else:\n",
    "                            break\n",
    "                    if numeric_sense_str:\n",
    "                        true_sense = int(numeric_sense_str)\n",
    "                    break\n",
    "                except (IndexError, ValueError):\n",
    "                    continue\n",
    "\n",
    "        if true_sense is None:\n",
    "            continue\n",
    "\n",
    "        total_predictions += 1\n",
    "       \n",
    "        predicted_sense = wsd_function(senses_keywords, sentence_tokens, window_size)\n",
    "        \n",
    "        if predicted_sense is not None and predicted_sense == true_sense:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    if total_predictions == 0:\n",
    "        return 0.0\n",
    "\n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    return accuracy\n",
    "\n",
    "score = evaluate_wsd(wsd_lesk, senses2, sentences)\n",
    "print(f\"Score de la méthode 'wsd_lesk': {score:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** En fixant au mieux la taille de la fenêtre autour de *interest*, quel est le meilleur score de la méthode de Lesk simplifiée ?  Quelle liste de sens conduit à de meilleurs scores, `senses1` ou `senses2` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va itérer sur 20 évaluations pour chaque taille de fenetre pour les deux listes (senses1 et senses2) pour avoir la moyenne des meilleurs scores\n",
    "window_sizes_to_test = [5, 7, 10, 12, 15, 17, 20]\n",
    "num_runs_for_averaging = 20\n",
    "\n",
    "results = {}\n",
    "\n",
    "for sense_list_name, sense_list_data in [(\"senses1\", senses1), (\"senses2\", senses2)]:\n",
    "    print(f\"Évaluation pour {sense_list_name}:\")\n",
    "    best_avg_score_for_senselist = -1\n",
    "    best_window_for_senselist = -1\n",
    "    all_scores_for_windows = {}\n",
    "    \n",
    "    for ws in window_sizes_to_test:\n",
    "        current_ws_scores = []\n",
    "        for run in range(num_runs_for_averaging):\n",
    "            score = evaluate_wsd(wsd_lesk, sense_list_data, sentences, window_size=ws)\n",
    "            current_ws_scores.append(score)\n",
    "        \n",
    "        avg_score = sum(current_ws_scores) / len(current_ws_scores) if current_ws_scores else 0\n",
    "        all_scores_for_windows[ws] = avg_score\n",
    "        print(f\"  Window size {ws}: Moyenne score sur {num_runs_for_averaging} exécutions = {avg_score:.2f}%\")\n",
    "        \n",
    "        if avg_score > best_avg_score_for_senselist:\n",
    "            best_avg_score_for_senselist = avg_score\n",
    "            best_window_for_senselist = ws\n",
    "            \n",
    "    results[sense_list_name] = {\n",
    "        'best_avg_score': best_avg_score_for_senselist,\n",
    "        'best_window': best_window_for_senselist,\n",
    "        'all_scores': all_scores_for_windows\n",
    "    }\n",
    "\n",
    "best_overall_score = -1\n",
    "best_overall_setup = \"\"\n",
    "\n",
    "for sense_name, data in results.items():\n",
    "    print(f\"Pour {sense_name}: Meilleur score moyen = {data['best_avg_score']:.2f}% (fenêtre = {data['best_window']})\")\n",
    "    if data['best_avg_score'] > best_overall_score:\n",
    "        best_overall_score = data['best_avg_score']\n",
    "        best_overall_setup = f\"avec {sense_name} et une fenêtre de {data['best_window']}\"\n",
    "\n",
    "print(f\"\\nLe meilleur score global (moyenné) de la méthode de Lesk simplifiée est : {best_overall_score:.2f}% {best_overall_setup}.\")\n",
    "\n",
    "if results.get(\"senses2\", {}).get('best_avg_score', -1) > results.get(\"senses1\", {}).get('best_avg_score', -1):\n",
    "    print(\"La liste de sens 'senses2' conduit à de meilleurs scores moyens.\")\n",
    "elif results.get(\"senses1\", {}).get('best_avg_score', -1) > results.get(\"senses2\", {}).get('best_avg_score', -1):\n",
    "    print(\"La liste de sens 'senses1' conduit à de meilleurs scores moyens.\")\n",
    "else:\n",
    "    if results.get(\"senses1\", {}).get('best_avg_score', -1) > -1 : # Vérifier qu'on a bien eu des scores\n",
    "        print(\"Les deux listes de sens conduisent à des scores moyens similaires (en considérant leur meilleure fenêtre respective).\")\n",
    "    else:\n",
    "        print(\"Impossible de déterminer quelle liste de sens est meilleure en raison de données/scores manquants.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme n'est pas déterministe, donc c'est difficile de savoir quel est la meilleure taille de la fenêtre. `senses2` conduit à des meilleurs scores et notre meilleur score obtenu est autour de 28% pour une taille de fenêtre de 17.\n",
    "\n",
    "Détail des résultats:\n",
    "\n",
    "```\n",
    "Évaluation pour senses1:\n",
    "  Window size 5: Moyenne score sur 20 exécutions = 19.71%\n",
    "  Window size 7: Moyenne score sur 20 exécutions = 19.74%\n",
    "  Window size 10: Moyenne score sur 20 exécutions = 20.39%\n",
    "  Window size 12: Moyenne score sur 20 exécutions = 20.62%\n",
    "  Window size 15: Moyenne score sur 20 exécutions = 20.70%\n",
    "  Window size 17: Moyenne score sur 20 exécutions = 20.81%\n",
    "  Window size 20: Moyenne score sur 20 exécutions = 21.37%\n",
    "Évaluation pour senses2:\n",
    "  Window size 5: Moyenne score sur 20 exécutions = 25.61%\n",
    "  Window size 7: Moyenne score sur 20 exécutions = 26.21%\n",
    "  Window size 10: Moyenne score sur 20 exécutions = 27.07%\n",
    "  Window size 12: Moyenne score sur 20 exécutions = 27.40%\n",
    "  Window size 15: Moyenne score sur 20 exécutions = 27.59%\n",
    "  Window size 17: Moyenne score sur 20 exécutions = 28.08%\n",
    "  Window size 20: Moyenne score sur 20 exécutions = 28.05%\n",
    "\n",
    "Pour senses1: Meilleur score moyen = 21.37% (fenêtre = 20)\n",
    "Pour senses2: Meilleur score moyen = 28.08% (fenêtre = 17)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utilisation de word2vec pour la similarité contexte vs. synset\n",
    "\n",
    "**3a.** En réutilisant une partie du code de `wsd_lesk`, veuillez maintenant définir une fonction `wsd_word2vec(senses, sentence)` qui choisit le sens en utilisant la similarité **word2vec** étudiée dans le labo précédent. \n",
    "* Vous pouvez chercher dans la [documentation des KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html) comment calculer directement la similarité entre deux listes de mots.\n",
    "* Comme `wsd_lesk`, la nouvelle fonction `wsd_word2vec` prend en argument une liste de listes de mots-clés par sens (comme `senses1` et `senses2` ci-dessus), et une phrase avec une occurrence annotée de *interest* ou *interests*.\n",
    "* La fonction retourne le numéro du sens le plus probable selon la similarité word2vec entre les mots du sens et ceux du voisinage de *interest*.  En cas d'égalité, tirer le sens au sort.\n",
    "* Vous pouvez régler la taille du voisinage (`window_size`) par l'expérimentation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "# path_to_model = \"../../../gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\"\n",
    "# wv_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "wv_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n",
    "def wsd_word2vec(senses, sentence, window_size=5):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Identify target word and its position\n",
    "    target_word_index = -1\n",
    "    target_word = None\n",
    "    for i, token in enumerate(sentence):\n",
    "        if token.startswith(\"interest_\") or token.startswith(\"interests_\"):\n",
    "            target_word_index = i\n",
    "            target_word = token.split(\"_\")[0]  # Get the actual word: \"interest\"\n",
    "            break\n",
    "\n",
    "    if target_word_index == -1 or target_word not in wv_model:\n",
    "        return random.randint(1, len(senses)) if senses else None\n",
    "\n",
    "    # Extract context tokens around the target word\n",
    "    start_index = max(0, target_word_index - window_size)\n",
    "    end_index = min(len(sentence), target_word_index + window_size + 1)\n",
    "    context_tokens_raw = sentence[start_index:target_word_index] + sentence[target_word_index+1:end_index]\n",
    "\n",
    "    # Clean context tokens\n",
    "    context_cleaned = [\n",
    "        token.lower() for token in context_tokens_raw\n",
    "        if token.isalpha() and token.lower() not in stop_words and token.lower() in wv_model\n",
    "    ]\n",
    "\n",
    "    if not context_cleaned:\n",
    "        return random.randint(1, len(senses)) if senses else None\n",
    "    \n",
    "    best_sense_indices = []\n",
    "    max_similarity = -float('inf') # Initialize with low value\n",
    "\n",
    "    for i, sense_kws in enumerate(senses):\n",
    "            sense_kws_in_vocab = [kw for kw in sense_kws if kw in wv_model]\n",
    "\n",
    "            if not sense_kws_in_vocab:\n",
    "                similarity = 0.0\n",
    "            else:\n",
    "                try:\n",
    "                    similarity = wv_model.n_similarity(context_cleaned, sense_kws_in_vocab)\n",
    "                except Exception as e:\n",
    "                    similarity = 0.0 \n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_sense_indices = [i + 1]\n",
    "            elif similarity == max_similarity:\n",
    "                if max_similarity > -float('inf'):\n",
    "                    best_sense_indices.append(i + 1)\n",
    "\n",
    "    if not best_sense_indices:\n",
    "        # No sense has been compared or every senses have no or a low similarity\n",
    "        return random.randint(1, len(senses)) if senses else None\n",
    "    elif len(best_sense_indices) == 1:\n",
    "        return best_sense_indices[0]\n",
    "    else:\n",
    "        # Equality, random choose bewtween the best\n",
    "        return random.choice(best_sense_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** Appliquez maintenant la même méthode `evaluate_wsd` avec la fonction `wsd_word2vec` (en cherchant une bonne valeur de la taille de la fenêtre) et affichez le score de la similarité word2vec.  Comment se compare-t-il avec le score précédent (Lesk) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n",
    "\n",
    "window_sizes_to_test_w2v = [5, 7, 10, 12, 15, 17, 20]\n",
    "num_runs_for_averaging_w2v = 20 \n",
    "results_w2v = {}\n",
    "\n",
    "for sense_list_name, sense_list_data in [(\"senses1\", senses1), (\"senses2\", senses2)]:\n",
    "    print(f\"Évaluation de wsd_word2vec pour {sense_list_name}:\")\n",
    "    best_avg_score_for_senselist = -1.0\n",
    "    best_window_for_senselist = -1\n",
    "    all_scores_for_windows = {}\n",
    "\n",
    "    for ws in window_sizes_to_test_w2v:\n",
    "        current_ws_scores = []\n",
    "        for run in range(num_runs_for_averaging_w2v):\n",
    "            score = evaluate_wsd(wsd_word2vec, sense_list_data, sentences, window_size=ws)\n",
    "            current_ws_scores.append(score)\n",
    "        \n",
    "        avg_score = sum(current_ws_scores) / len(current_ws_scores) if current_ws_scores else 0.0\n",
    "        all_scores_for_windows[ws] = avg_score\n",
    "        print(f\"  Window size {ws}: Moyenne score sur {num_runs_for_averaging_w2v} exécutions = {avg_score:.2f}%\")\n",
    "        \n",
    "        if avg_score > best_avg_score_for_senselist:\n",
    "            best_avg_score_for_senselist = avg_score\n",
    "            best_window_for_senselist = ws\n",
    "            \n",
    "    results_w2v[sense_list_name] = {\n",
    "        'best_avg_score': best_avg_score_for_senselist,\n",
    "        'best_window': best_window_for_senselist,\n",
    "        'all_scores': all_scores_for_windows\n",
    "    }\n",
    "\n",
    "# Affichage et comparaison des meilleurs scores pour wsd_word2vec\n",
    "best_overall_score_w2v = -1.0\n",
    "best_overall_setup_w2v = \"\"\n",
    "s1_data_w2v = results_w2v.get(\"senses1\", {'best_avg_score': -1.0, 'best_window': 'N/A'})\n",
    "s2_data_w2v = results_w2v.get(\"senses2\", {'best_avg_score': -1.0, 'best_window': 'N/A'})\n",
    "if s1_data_w2v['best_avg_score'] > -1.0 :\n",
    "    print(f\"Pour senses1 avec wsd_word2vec: Meilleur score moyen = {s1_data_w2v['best_avg_score']:.2f}% (fenêtre = {s1_data_w2v['best_window']})\")\n",
    "    if s1_data_w2v['best_avg_score'] > best_overall_score_w2v:\n",
    "        best_overall_score_w2v = s1_data_w2v['best_avg_score']\n",
    "        best_overall_setup_w2v = f\"avec senses1 et une fenêtre de {s1_data_w2v['best_window']}\"\n",
    "if s2_data_w2v['best_avg_score'] > -1.0 :\n",
    "    print(f\"Pour senses2 avec wsd_word2vec: Meilleur score moyen = {s2_data_w2v['best_avg_score']:.2f}% (fenêtre = {s2_data_w2v['best_window']})\")\n",
    "    if s2_data_w2v['best_avg_score'] > best_overall_score_w2v:\n",
    "        best_overall_score_w2v = s2_data_w2v['best_avg_score']\n",
    "        best_overall_setup_w2v = f\"avec senses2 et une fenêtre de {s2_data_w2v['best_window']}\"\n",
    "if best_overall_score_w2v > -1.0:\n",
    "    print(f\"\\nLe meilleur score global (moyenné) pour wsd_word2vec est : {best_overall_score_w2v:.2f}% {best_overall_setup_w2v}.\")\n",
    "    if s2_data_w2v['best_avg_score'] > s1_data_w2v['best_avg_score']:\n",
    "        print(\"La liste de sens 'senses2' conduit à de meilleurs scores moyens avec wsd_word2vec.\")\n",
    "    elif s1_data_w2v['best_avg_score'] > s2_data_w2v['best_avg_score']:\n",
    "        print(\"La liste de sens 'senses1' conduit à de meilleurs scores moyens avec wsd_word2vec.\")\n",
    "    else:\n",
    "        print(\"Les deux listes de sens conduisent à des scores moyens similaires avec wsd_word2vec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode wsd_word2vec surpasse la méthode de Lesk simplifiée. La précision passe d'environ 28% pour Lesk à environ 64% pour Word2Vec.\n",
    "\n",
    "L'utilisation des embeddings de mots pour capturer la similarité entre le contexte et les définitions des sens est beaucoup plus efficace que le simple comptage de mots en commun. Dans les deux cas, la liste de mots-clés senses2 a conduit à de meilleurs scores que senses1. La quautité et la qualité des mots-clés permettent une meilleure performance.\n",
    "\n",
    "Détail des résultats:\n",
    "\n",
    "```\n",
    "Évaluation de wsd_word2vec pour senses1:\n",
    "  Window size 5: Moyenne score sur 20 exécutions = 39.01%\n",
    "  Window size 7: Moyenne score sur 20 exécutions = 39.90%\n",
    "  Window size 10: Moyenne score sur 20 exécutions = 40.23%\n",
    "  Window size 12: Moyenne score sur 20 exécutions = 41.45%\n",
    "  Window size 15: Moyenne score sur 20 exécutions = 40.15%\n",
    "  Window size 17: Moyenne score sur 20 exécutions = 40.88%\n",
    "  Window size 20: Moyenne score sur 20 exécutions = 41.29%\n",
    "\n",
    "Évaluation de wsd_word2vec pour senses2:\n",
    "  Window size 5: Moyenne score sur 20 exécutions = 63.60%\n",
    "  Window size 7: Moyenne score sur 20 exécutions = 63.11%\n",
    "  Window size 10: Moyenne score sur 20 exécutions = 62.13%\n",
    "  Window size 12: Moyenne score sur 20 exécutions = 64.01%\n",
    "  Window size 15: Moyenne score sur 20 exécutions = 62.95%\n",
    "  Window size 17: Moyenne score sur 20 exécutions = 62.79%\n",
    "  Window size 20: Moyenne score sur 20 exécutions = 63.52%\n",
    "Pour senses1 avec wsd_word2vec: Meilleur score moyen = 41.45% (fenêtre = 12)\n",
    "Pour senses2 avec wsd_word2vec: Meilleur score moyen = 64.01% (fenêtre = 12)\n",
    "\n",
    "Le meilleur score global (moyenné) pour wsd_word2vec est : 64.01% avec senses2 et une fenêtre de 12.\n",
    "La liste de sens 'senses2' conduit à de meilleurs scores moyens avec wsd_word2vec.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification supervisée avec des traits lexicaux\n",
    "Vous entraînerez maintenant des classifieurs pour prédire le sens d'une occurrence dans une phrase.  Le premier but sera de transformer chaque phrase en un ensemble d'attributs pour formater les données en vue des expériences de classification.\n",
    "\n",
    "Veuillez utiliser le classifieur `NaiveBayesClassifier` fourni par NLTK.  Le mode d'emploi se trouve dans le [Chapitre 6, sections 1.1-1.3](https://www.nltk.org/book/ch06.html) du livre NLTK.  Consultez-le attentivement pour trouver comment formater les données.  De plus, il faudra séparer les données en sous-ensembles d'entraînement et de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vous propose de nommer les attributs `word-k`, ..., `word-2`, `word-1`, `word+1`, `word+2`, ..., `word+k` (fenêtre de taille `2*k` autour de *interest*).  Leurs valeurs sont les mots observés aux emplacements respectifs, ou `NONE` si la position dépasse l'étendue de la phrase.  Vous ajouterez un attribut nommé `word0` qui est l'occurrence du mot *interest* au singulier ou au pluriel.  \n",
    "\n",
    "Pour chaque occurrence de *interest*, vous devrez donc créer la représentation suivante (où `6` est le numéro du sens, essentiel pour l'entraînement, mais à cacher lors de l'évaluation) :\n",
    "```\n",
    "[{'word-1': 'in', 'word+1': 'rates', 'word-2': 'declines', 'word+2': 'NONE', 'word0': 'interest'}, 6]\n",
    "```\n",
    "\n",
    "**4a.** En partant de la liste des phrases appelée `sentences` préparée plus haut, veuillez générer la liste avec toutes les représentation, appelée `items_with_features`.  Vous pouvez vous aider du livre NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez répondre ici à la question.\n",
    "\n",
    "items_with_features = []\n",
    "window_half_size = 2 # Pour avoir word-2, word-1, word+1, word+2 (k=2)\n",
    "\n",
    "for sentence_idx, sentence_tokens in enumerate(sentences):\n",
    "    target_indices = []\n",
    "    # Trouver tous les index des occurrences de 'interest_X' ou 'interests_X'\n",
    "    for token_idx, token in enumerate(sentence_tokens):\n",
    "        if token.startswith(\"interest_\") or token.startswith(\"interests_\"):\n",
    "            target_indices.append(token_idx)\n",
    "\n",
    "    for target_idx in target_indices:\n",
    "        numeric_sense = None\n",
    "        target_token_full = sentence_tokens[target_idx] # ex: interest_6\n",
    "        \n",
    "        try:\n",
    "            sense_part = target_token_full.split('_')[-1]\n",
    "            # Extraire uniquement la partie numérique du sens\n",
    "            numeric_sense_str = \"\".join(filter(str.isdigit, sense_part))\n",
    "            if numeric_sense_str: # S'assurer qu'on a bien extrait des chiffres\n",
    "                numeric_sense = int(numeric_sense_str)\n",
    "            else:\n",
    "                continue\n",
    "        except (IndexError, ValueError):\n",
    "            continue\n",
    "\n",
    "        features = {}\n",
    "        \n",
    "        # On prend le mot avant le _ (interest ou interests)\n",
    "        features['word0'] = target_token_full.split('_')[0]\n",
    "\n",
    "        # Attributs word-k à word+k\n",
    "        for k_offset in range(1, window_half_size + 1):\n",
    "            # Contexte avant (word-k)\n",
    "            prev_idx = target_idx - k_offset\n",
    "            if prev_idx >= 0:\n",
    "                features[f'word-{k_offset}'] = sentence_tokens[prev_idx].lower()\n",
    "            else:\n",
    "                features[f'word-{k_offset}'] = 'NONE'\n",
    "\n",
    "            # Contexte après (word+k)\n",
    "            next_idx = target_idx + k_offset\n",
    "            if next_idx < len(sentence_tokens):\n",
    "                features[f'word+{k_offset}'] = sentence_tokens[next_idx].lower()\n",
    "            else:\n",
    "                features[f'word+{k_offset}'] = 'NONE'\n",
    "        \n",
    "        items_with_features.append((features, numeric_sense))\n",
    "        \n",
    "print(f\"Nombre total d'items avec features générés : {len(items_with_features)}\")\n",
    "if len(items_with_features) > 153:\n",
    "    print(\"\\nExemples d'items_with_features :\")\n",
    "    for i in range(151, min(154, len(items_with_features))):\n",
    "        print(items_with_features[i])\n",
    "else:\n",
    "    print(\"\\nMoins de 154 items générés, affichage des premiers:\")\n",
    "    for i in range(min(3, len(items_with_features))):\n",
    "        print(items_with_features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b.** Veuillez séparer les données aléatoirement en 80% pour l'entraînement et 20%  pour l'évaluation.  Veuillez faire une division stratifiée : les deux sous-ensembles doivent contenir les mêmes proportions de sens que l'ensemble de départ.  Ils seront appelés `iwf_train` et `iwf_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iwf_train = []\n",
    "iwf_test  = []\n",
    "\n",
    "# Veuillez répondre ici à la question.\n",
    "\n",
    "def stratified_split(items_with_features_list, train_ratio=0.8):\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    items_by_label = defaultdict(list)\n",
    "    for item in items_with_features_list:\n",
    "        # S'assurer que l'item est bien un tuple (ou liste) de 2 éléments\n",
    "        if isinstance(item, (list, tuple)) and len(item) == 2:\n",
    "            items_by_label[item[1]].append(item) # item[1] est le label\n",
    "        else:\n",
    "            # Gérer le cas où un item n'a pas le bon format, si nécessaire\n",
    "            pass\n",
    "\n",
    "    for label, items in items_by_label.items():\n",
    "        shuffle(items) # Mélanger au sein de la classe\n",
    "        \n",
    "        # Calcul du point de partage\n",
    "        split_idx = int(len(items) * train_ratio)\n",
    "        \n",
    "        train_set.extend(items[:split_idx])\n",
    "        test_set.extend(items[split_idx:])\n",
    "    \n",
    "    shuffle(train_set) # Mélanger l'ensemble d'entraînement final\n",
    "    shuffle(test_set)  # Mélanger l'ensemble de test final\n",
    "    return train_set, test_set\n",
    "\n",
    "iwf_train, iwf_test = stratified_split(items_with_features)\n",
    "print(f\"\\nTaille de l'ensemble d'entraînement : {len(iwf_train)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(iwf_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Veuillez créer une instance de `NaiveBayesClassifier`, l'entraîner sur `iwf_train` et la tester sur `iwf_test` (voir la documentation NLTK).  En expérimentant avec différentes largeurs de fenêtres, quel est le meilleur score que vous obtenez (avec la fonction `accuracy` de NLTK) sur l'ensemble de test ?  Comment se compare-t-il avec les précédents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "# Génère la liste des (featureset, label) pour la classification.\n",
    "def generate_features_for_classification(sentences_data, window_k):\n",
    "    items = []\n",
    "    for sentence_tokens in sentences_data:\n",
    "        target_indices = [i for i, token in enumerate(sentence_tokens)\n",
    "                          if token.startswith(\"interest_\") or token.startswith(\"interests_\")]\n",
    "\n",
    "        for target_idx in target_indices:\n",
    "            numeric_sense = None\n",
    "            target_token_full = sentence_tokens[target_idx]\n",
    "            sense_part = target_token_full.split('_')[-1]\n",
    "            numeric_sense_str = \"\".join(filter(str.isdigit, sense_part))\n",
    "            if numeric_sense_str: numeric_sense = int(numeric_sense_str)\n",
    "            else: continue\n",
    "\n",
    "            features = {}\n",
    "            features['word0'] = target_token_full.split('_')[0].lower()\n",
    "\n",
    "            for k_offset in range(1, window_k + 1):\n",
    "                features[f'word-{k_offset}'] = sentence_tokens[target_idx - k_offset].lower() if (target_idx - k_offset) >= 0 else 'NONE'\n",
    "                features[f'word+{k_offset}'] = sentence_tokens[target_idx + k_offset].lower() if (target_idx + k_offset) < len(sentence_tokens) else 'NONE'\n",
    "            \n",
    "            items.append((features, numeric_sense))\n",
    "    return items\n",
    "\n",
    "# Définir les tailles de demi-fenêtre (k) à tester\n",
    "window_k_values_to_test = [1, 2, 3, 4, 5, 7, 10] \n",
    "best_nb_accuracy = -1.0\n",
    "best_nb_window_k = -1\n",
    "for k_val in window_k_values_to_test:\n",
    "    current_items_with_features = generate_features_for_classification(sentences, window_k=k_val)\n",
    "    if not current_items_with_features:\n",
    "        continue\n",
    "\n",
    "    # Division stratifiée\n",
    "    iwf_train, iwf_test = stratified_split(current_items_with_features, train_ratio=0.8)\n",
    "    if not iwf_train or not iwf_test:\n",
    "        continue\n",
    "    \n",
    "    # Entraînement du classifieur NaiveBayes\n",
    "    classifier_nb = NaiveBayesClassifier.train(iwf_train)\n",
    "\n",
    "    # Test du classifieur\n",
    "    current_accuracy = accuracy(classifier_nb, iwf_test) * 100 # en pourcentage\n",
    "    print(f\"  Accuracy pour k={k_val}: {current_accuracy:.2f}%\")\n",
    "    if current_accuracy > best_nb_accuracy:\n",
    "        best_nb_accuracy = current_accuracy\n",
    "        best_nb_window_k = k_val\n",
    "\n",
    "print(f\"\\n--- Résultat pour NaiveBayesClassifier ---\")\n",
    "if best_nb_window_k != -1:\n",
    "    print(f\"Meilleur score d'accuracy obtenu : {best_nb_accuracy:.2f}%\")\n",
    "    print(f\"Avec une demi-taille de fenêtre (k) = {best_nb_window_k} (donc {2*best_nb_window_k} mots de contexte + word0).\")\n",
    "\n",
    "print(f\"\\n--- Comparaison des scores ---\")\n",
    "best_lesk_score = 28.08\n",
    "best_w2v_score = 64.01\n",
    "print(f\"Meilleur score Lesk simplifié : {best_lesk_score:.2f}%\")\n",
    "print(f\"Meilleur score Word2Vec       : {best_w2v_score:.2f}%\")\n",
    "if best_nb_window_k != -1:\n",
    "    print(f\"Meilleur score NaiveBayes     : {best_nb_accuracy:.2f}%\")\n",
    "    if best_nb_accuracy > best_w2v_score and best_nb_accuracy > best_lesk_score:\n",
    "        print(\"\\nNaiveBayes a obtenu le meilleur score global.\")\n",
    "    elif best_w2v_score > best_nb_accuracy and best_w2v_score > best_lesk_score:\n",
    "        print(\"\\nWord2Vec a obtenu le meilleur score global.\")\n",
    "    elif best_lesk_score > best_nb_accuracy and best_lesk_score > best_w2v_score:\n",
    "        print(\"\\nLesk simplifié a obtenu le meilleur score global.\")\n",
    "    else:\n",
    "        # Gérer les autres cas d'égalité ou de classement\n",
    "        scores_dict = {\"Lesk\": best_lesk_score, \"Word2Vec\": best_w2v_score, \"NaiveBayes\": best_nb_accuracy}\n",
    "        sorted_scores = sorted(scores_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "        print(\"\\nClassement des méthodes :\")\n",
    "        for method, score_val in sorted_scores:\n",
    "            print(f\"  - {method}: {score_val:.2f}%\")\n",
    "else:\n",
    "    print(\"Impossible de comparer avec NaiveBayes car aucun score valide n'a été obtenu.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleur score avec `accuracy` : 85.08% avec une demi-taille de fenêtre (k) = 3 (donc 6 mots de contexte + word0).\n",
    "\n",
    "Comparaison des scores:\n",
    "* Meilleur score Lesk simplifié : 28.08%\n",
    "* Meilleur score Word2Vec       : 64.01%\n",
    "* Meilleur score NaiveBayes     : 85.08%\n",
    "\n",
    "NaiveBayes a obtenu le meilleur score global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d.** En utilisant la fonction `show_most_informative_features()`, veuillez afficher les attributs les plus informatifs et commenter le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ré-entraînement du classifieur final avec la meilleure demi-fenêtre\n",
    "window = 3\n",
    "items_final_features = generate_features_for_classification(sentences, window)\n",
    "iwf_train_final, iwf_test_final = stratified_split(items_final_features, train_ratio=0.8) \n",
    "classifier_final_nb = NaiveBayesClassifier.train(iwf_train_final)\n",
    "print(f\"  Accuracy pour k={window}: {accuracy(classifier_final_nb, iwf_test_final) * 100 :.2f}%\")\n",
    "\n",
    "num_informative_features_to_show = 10\n",
    "print(f\"\\nLes {num_informative_features_to_show} attributs les plus informatifs (k={window}):\")\n",
    "classifier_final_nb.show_most_informative_features(num_informative_features_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats:\n",
    "\n",
    "```\n",
    "Accuracy pour k=3: 84.68%\n",
    "\n",
    "Les 10 attributs les plus informatifs (k=3):\n",
    "Most Informative Features\n",
    "                   word0 = 'interests'         3 : 1      =     68.7 : 1.0\n",
    "                  word+1 = 'in'                1 : 6      =     54.2 : 1.0\n",
    "                  word+1 = 'of'                4 : 6      =     37.7 : 1.0\n",
    "                  word-1 = 'other'             3 : 6      =     19.9 : 1.0\n",
    "                  word+2 = ','                 6 : 5      =     16.2 : 1.0\n",
    "                  word-2 = 'have'              1 : 6      =     14.4 : 1.0\n",
    "                  word-2 = 'company'           5 : 6      =     10.4 : 1.0\n",
    "                  word-2 = 'NONE'              6 : 4      =     10.2 : 1.0\n",
    "                  word+2 = 'the'               1 : 2      =      9.9 : 1.0\n",
    "                  word-1 = 'in'                6 : 5      =      9.7 : 1.0\n",
    "```\n",
    "\n",
    "* word0 = 'interests' 3 : 1 = 68.7 :  Si le mot cible est \"interests\" (pluriel), il est plus probable que ce soit le sens 3 (activité/hobby) que le sens 1 (curiosité/attention). Le pluriel \"interests\" est associé aux activités (sens 5), tandis que le sens 1 est souvent au singulier.\n",
    "* word+1 = 'in' 1 : 6 = 54.2 : Si le mot immédiatement après \"interest(s)\" est \"in\", il est très probable que ce soit le sens 1 plutôt que le sens 6 (financier). C'est cohérent avec la structure \"interest in [quelque chose]\".\n",
    "* word+1 = 'of' 4 : 6 = 37.7 : Si le mot suivant est \"of\", il est bien plus probable que ce soit le sens 4 (avantage, \"the interest of...\") que le sens 6. Capture la structure \"interest of [entité/groupe]\" typique du sens 4.\n",
    "* word-1 = 'other' 3 : 6 = 19.9 : Si le mot précédant \"interest(s)\" est \"other\", il est très probable que ce soit le sens 3 (activités/hobbies) plutôt que le sens 6.\n",
    "* word+2 = ',' 6 : 5 = 16.2 : Si le mot en position +2 est une virgule, il est plus probable que ce soit le sens 6 (financier) que le sens 5 (part dans une entreprise). Suggère des structures de phrases où une information financière sur \"interest\" est suivie d'une clause (par exemple, \"interest rates, which have fallen,...\", \"principal and interest, amounted to...\").\n",
    "* word-2 = 'have' 1 : 6 = 14.4 : Si deux mots avant \"interest(s)\" on a \"have\" (ex: \"they have an interest in...\"), il est plus probable que ce soit le sens 1 que le sens 6. La construction \"to have an interest in\" est typique du sens 1.\n",
    "* word-2 = 'company' 5 : 6 = 10.4 : Si le mot deux positions avant \"interest(s)\" est \"company\" (ex: \"the company's interest in...\"), il est bien plus probable que ce soit le sens 5 (part dans une entreprise) que le sens 6.\n",
    "* word-2 = 'NONE' 6 : 4 = 10.2 : Si \"interest(s)\" apparaît comme le deuxième mot de la phrase, il est plus probable que ce soit le sens 6 que le sens 4. NONE à word-2 signifie que interest(s) est précédé d'au plus un mot. Cela pourrait correspondre à des phrases commençant par \"Interest rates...\" ou \"The interest was...\".\n",
    "* word+2 = 'the' 1 : 2 = 9.9 : Si deux mots après \"interest(s)\" on a \"the\" (ex: \"interest in the outcome\"), il est plus probable que ce soit le sens 1 que le sens 2. Le sens 2 étant de toute façon très rare et probablement mal prédit. \"interest in the...\" est une structure courante pour le sens 1.\n",
    "* word-1 = 'in' 6 : 5 = 9.7 : Si le mot précédant \"interest(s)\" est \"in\" (ex: \"decline in interest rates\"), il est plus probable que ce soit le sens 6 (financier) que le sens 5 (part dans une entreprise).\n",
    "\n",
    "Les features les plus informatives restent largement basées sur des mots fonctionnels dans des positions ou la forme du mot \"interest\" lui-même. Le fait que l'accuracy soit toujours élevée (84.68%) montre que ces features positionnelles, même simples, sont très efficaces pour cette tâche avec Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4e.** On souhaite également obtenir les scores pour chaque sens.  Pour ce faire, il faut demander les prédictions une par une au classifieur (voir le [livre NLTK](https://www.nltk.org/book/ch06.html)), et comptabiliser les prédictions correctes pour chaque sens.  Vous pouvez vous inspirer de `evaluate_wsd`, et écrire une fonction `evaluate_wsd_supervised(classifier, items_with_features)`, que vous appliquerez aux donnés `iwf_test`.  Veuillez afficher ces scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_wsd_supervised(classifier, items_with_features_test_set):\n",
    "    true_positives = defaultdict(int)\n",
    "    false_positives = defaultdict(int)\n",
    "    false_negatives = defaultdict(int)\n",
    "    \n",
    "    reference_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for featureset, true_label in items_with_features_test_set:\n",
    "        predicted_label = classifier.classify(featureset)\n",
    "        reference_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    all_labels = sorted(list(set(reference_labels) | set(predicted_labels)))\n",
    "    if not all_labels:\n",
    "        print(\"Aucun label trouvé dans les données de test ou les prédictions.\")\n",
    "        return\n",
    "\n",
    "    for true_label, predicted_label in zip(reference_labels, predicted_labels):\n",
    "        if true_label == predicted_label:\n",
    "            true_positives[true_label] += 1\n",
    "        else:\n",
    "            false_positives[predicted_label] += 1\n",
    "            false_negatives[true_label] += 1\n",
    "\n",
    "    print(f\"{'Sens'} | {'Précision'} | {'Rappel'} | {'Score F1'}\")\n",
    "    print(\"-\" * 37)\n",
    "\n",
    "    weighted_avg_f1_numerator = 0\n",
    "    total_support = 0\n",
    "    f1_scores_for_macro_avg = [] # Liste pour stocker les F1 scores de chaque classe\n",
    "\n",
    "    for L in all_labels: # Renommé 'label' en 'L' pour éviter conflit avec 'label' de la boucle externe\n",
    "        tp = true_positives[L]\n",
    "        fp = false_positives[L]\n",
    "        fn = false_negatives[L]\n",
    "        \n",
    "        support = tp + fn \n",
    "\n",
    "        precision_score = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall_score = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            \n",
    "        if (precision_score + recall_score) == 0:\n",
    "            f1_score = 0.0\n",
    "        else:\n",
    "            f1_score = 2 * (precision_score * recall_score) / (precision_score + recall_score)\n",
    "        \n",
    "        f1_scores_for_macro_avg.append(f1_score) # Ajouter le F1 score pour la moyenne macro\n",
    "            \n",
    "        print(f\"{L:<4} | {precision_score:<9.2f} | {recall_score:<6.2f} | {f1_score:<7.2f}\")\n",
    "\n",
    "        weighted_avg_f1_numerator += f1_score * support\n",
    "        total_support += support\n",
    "    \n",
    "    if total_support > 0:\n",
    "        # Calcul du Macro Average F1 (moyenne simple des F1 scores)\n",
    "        macro_avg_f1 = sum(f1_scores_for_macro_avg) / len(f1_scores_for_macro_avg) if f1_scores_for_macro_avg else 0.0\n",
    "        \n",
    "        # Calcul du Weighted Average F1\n",
    "        weighted_avg_f1 = weighted_avg_f1_numerator / total_support\n",
    "        \n",
    "        print(\"-\" * 37)\n",
    "        print(f\"Macro Avg F1: {macro_avg_f1:.2f}\")\n",
    "        print(f\"Weighted Avg F1: {weighted_avg_f1:.2f}\")\n",
    "\n",
    "evaluate_wsd_supervised(classifier_final_nb, iwf_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores obtenus:\n",
    "```\n",
    "Sens | Précision | Rappel | Score F1\n",
    "-------------------------------------\n",
    "1    | 0.67      | 0.82   | 0.74   \n",
    "2    | 0.00      | 0.00   | 0.00   \n",
    "3    | 0.60      | 0.38   | 0.46   \n",
    "4    | 0.62      | 0.78   | 0.69   \n",
    "5    | 0.76      | 0.69   | 0.72   \n",
    "6    | 0.99      | 0.94   | 0.96   \n",
    "-------------------------------------\n",
    "Macro Avg F1: 0.60\n",
    "Weighted Avg F1: 0.85\n",
    "```\n",
    "\n",
    "Note concernant le sens 2: Ce sens est soit absent de l'ensemble de test, soit le classifieur ne l'a jamais correctement prédit (et n'a probablement jamais essayé de le prédire en raison de sa rareté dans l'ensemble d'entraînement). C'est un point faible évident, principalement dû au manque de données pour ce sens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "Veuillez recopier ci-dessous, en guise de conclusion, les scores des trois expériences réalisées, pour pouvoir les comparer d'un coup d'oeil.  Quel est le meilleur score obtenu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Comparaison des scores:\n",
    "# Meilleur score Lesk simplifié : 28.08%\n",
    "# Meilleur score Word2Vec       : 64.01%\n",
    "# Meilleur score NaiveBayes     : 85.08% --> Meilleur score obtenu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire\n",
    "\n",
    "Merci de nettoyer votre feuille, sauvegarder le résultat, et soumettre le *notebook* sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
